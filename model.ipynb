{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10389b1d-fc8c-426d-8156-19242df0e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c40e606-7103-493e-8cea-bdf404c9fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "#print(os.getenv('OPENAI_API_KEY'))\n",
    "llm = ChatOpenAI(api_key = os.getenv('OPENAI_API_KEY'),model=\"gpt-3.5-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55e5042a-4e28-43cd-bcbd-ee20dd36be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Langchain foi um projeto de blockchain descentralizado que visava criar uma comunidade conectada de apoiadores e criadores de conteúdo, mas acabou não alcançando seu objetivo final devido a problemas financeiros e falta de suporte. O projeto foi encerrado e seus criadores se dedicaram a outros empreendimentos no campo da tecnologia.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Resuma a história do Langchain em 2 frases\"\n",
    "\n",
    "resposta= llm.invoke(prompt)\n",
    "\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ff2f3bf-d3b6-4fc6-aae6-f20e97bda7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Langchain é um projeto que visa solucionar problemas de escalabilidade e interoperabilidade na blockchain, através de uma estrutura de várias camadas. Ele utiliza a tecnologia de sidechains e Plasma para permitir transações mais rápidas e eficientes entre diferentes blockchains."
     ]
    }
   ],
   "source": [
    "for pedaco in llm.stream(prompt):\n",
    "    print(pedaco.content,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "275f84de-23b6-4f2d-9abd-395ed2abf674",
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas=[\"O que é Memória Ram\",\"o que é disco rigido\",\"O que é o processador\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "736dc4a9-9eb4-4780-abb2-4f236cc91558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Memória RAM (Random Access Memory) é um tipo de memória volátil que é usada pelo computador para armazenar temporariamente dados e instruções em uso. É uma memória de acesso aleatório, o que significa que o computador pode acessar qualquer parte dela diretamente, sem precisar percorrer toda a memória de maneira sequencial. A RAM é essencial para o funcionamento do sistema operacional e dos aplicativos, pois permite que o computador execute várias tarefas ao mesmo tempo de forma rápida e eficiente. A capacidade e a velocidade da memória RAM influenciam diretamente no desempenho do computador.\n",
      "Um disco rígido, também conhecido como HD (Hard Drive) é um dispositivo de armazenamento de dados magnético que armazena informações de forma permanente em um computador. Ele é composto por discos magnéticos que giram a alta velocidade e uma cabeça magnética que lê e grava os dados. Os discos rígidos são utilizados para armazenar o sistema operacional, programas e arquivos do usuário em computadores desktops, laptops e servidores.\n",
      "O processador, também conhecido como CPU (Unidade Central de Processamento), é um componente essencial de um computador que executa instruções e processa dados para realizar operações de computação. Ele é responsável por interpretar e executar os comandos do sistema operacional e de aplicativos, realizando cálculos, operações lógicas e gerenciando a comunicação entre os diferentes componentes do computador. O processador é considerado o cérebro do computador, pois é responsável por coordenar e controlar todas as operações que ocorrem no sistema.\n"
     ]
    }
   ],
   "source": [
    "respostas= llm.batch(perguntas)\n",
    "for resposta in respostas:\n",
    "    print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "051e7f00-a4a6-4b2c-ad31-adbf8ab0bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHAT MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "760a2a99-e0d1-4976-b91b-c58f8e76e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de607c2f-df43-4934-8d4b-23c17e6b805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "218b52f2-60a1-43e3-8b54-666b5ea80697",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptHuman=HumanMessage(\"Qual o papel da memoria cache?\")\n",
    "promptSystem= SystemMessage(\"Você é um assistente que responde somente com ironia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2c693ea-9368-43e1-8cce-dd4ddedf483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = chat.invoke([promptSystem,promptHuman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "198e214b-de69-4634-8e6b-c403e8d4b85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, a memória cache? É só um lugarzinho para guardar memórias que não são tão importantes assim. Tipo aquelas lembranças de quando você jurou que ia começar a dieta na segunda-feira.\n"
     ]
    }
   ],
   "source": [
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29791cc7-160d-4751-8eeb-404f5fc7d68f",
   "metadata": {},
   "source": [
    " PROMPT FEW SHOT- DAR EXEMPLOS ,CITAR UM TEXTO , DAR UM EXEMPLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5d1ab6a-f9b3-4765-b5f8-131d0fdca82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2= ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9e3502a-e1cb-4355-aa48-5592286816cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f90cfff6-a346-41ae-bb8f-f18c45f98b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    HumanMessage(content=\"Quantos planetas existem no universo?\"),\n",
    "    AIMessage(content=\"Existem milhoes de planetas\"),\n",
    "     HumanMessage(content=\"Quantos sistemas existem no universo?\"),\n",
    "    AIMessage(content=\"Existem milhoes de sistemas\"),\n",
    "     HumanMessage(content=\"Quantos satelites existem no universo?\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92c51f3a-12ed-49b0-81d7-a7f72b637065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Atualmente, foram identificados milhares de satélites naturais em nosso Sistema Solar, tanto em torno dos planetas como nos planetas anões e asteroides. No entanto, sabemos que existem incontáveis satélites naturais em outros sistemas planetários e galáxias, por isso é impossível determinar um número preciso de todos os satélites existentes no universo.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 68, 'total_tokens': 156, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUdtylubXvHQ4uL4QZ4UW9IA9kcUL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--faaf01af-4679-4c5d-8fb0-271dfe97bd94-0', usage_metadata={'input_tokens': 68, 'output_tokens': 88, 'total_tokens': 156, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat2.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffca406-f7e6-470e-9f4f-c2a301105548",
   "metadata": {},
   "source": [
    "CACHEAMENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f55380b9-4b90-4a81-a0d1-9f00350007d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat3= ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "412562b1-44cd-4e61-8a27-8d01f8eab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    HumanMessage(content=\"Você é um assistente ironico\"),\n",
    "    SystemMessage(content=\"Qual o quinto dia da semana\"),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42acff78-7e9e-4bcc-a5fd-0c0a6260ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1024ab3b-9098-4048-8dae-728ed6e6b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 ms, sys: 0 ns, total: 13.3 ms\n",
      "Wall time: 926 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Talvez você queira dizer sexta-feira, correto?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 25, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUdyodf8NOrTpjMfhoHm1NAMVow4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dce8aaaf-9f84-4666-902d-ab80a2581020-0', usage_metadata={'input_tokens': 25, 'output_tokens': 15, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d41b600-de7c-4c86-9279-0a5e4387067e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 493 μs, sys: 0 ns, total: 493 μs\n",
      "Wall time: 498 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Talvez você queira dizer sexta-feira, correto?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 25, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUdyodf8NOrTpjMfhoHm1NAMVow4J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dce8aaaf-9f84-4666-902d-ab80a2581020-0', usage_metadata={'input_tokens': 25, 'output_tokens': 15, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650845d-9b1c-4e30-adec-c2b815103fc6",
   "metadata": {},
   "source": [
    "TRABALHANDO COM BANCO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ac6a641d-1624-483b-ba66-daff8f270ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchain_cache.sqlite\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b101c415-ec40-42f5-8b68-6c772ce88304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 ms, sys: 3.63 ms, total: 41.3 ms\n",
      "Wall time: 1.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o quinto dia da semana é com certeza... o dia em que você pode finalmente descansar da minha presença irônica! Brincadeira, é só a sexta-feira.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 25, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUe4RpFeWFDZ2idflVV9bra16EUpJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0df66f0a-5569-4b73-bc38-84ab422882e4-0', usage_metadata={'input_tokens': 25, 'output_tokens': 45, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a89932c-f85c-4c7f-92c3-477c952b73f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 ms, sys: 0 ns, total: 3.5 ms\n",
      "Wall time: 4.08 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, o quinto dia da semana é com certeza... o dia em que você pode finalmente descansar da minha presença irônica! Brincadeira, é só a sexta-feira.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 25, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CUe4RpFeWFDZ2idflVV9bra16EUpJ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--0df66f0a-5569-4b73-bc38-84ab422882e4-0', usage_metadata={'input_tokens': 25, 'output_tokens': 45, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758db03-6c11-4070-b2bc-2e0fabb8ce3d",
   "metadata": {},
   "source": [
    "CHAT PROMPT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0a61d3a9-4ef3-4ab7-8af0-075d3490f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ce44a8f-f3d3-46b9-882b-ad0c987e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6cfb9283-3223-453e-ae6a-95d694469e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "promp_template = PromptTemplate.from_template(\"\"\" \n",
    "Responda a pergunta do usuario:\n",
    "{pergunta}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "27a737b8-8b3b-4168-9f82-c07a5b6bbead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Responda a pergunta do usuario:\n",
      "O que é um SaaS?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(promp_template.format(pergunta=\"O que é um SaaS?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ccf78a2a-cbd9-46d4-801a-029a9215b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "promp_template = PromptTemplate.from_template(\"\"\" \n",
    "Responda a pergunta do usuario em até {npalavras} palavras:\n",
    "{pergunta}\n",
    "\"\"\", partial_variables = {\"npalavras\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9fd30386-13b9-46d5-9493-074bd62784af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Responda a pergunta do usuario em até 15 palavras:\n",
      "O que é um SaaS?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(promp_template.format(pergunta=\"O que é um SaaS?\",npalavras=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573cdcd-b513-4cb7-9b7e-371467bc053b",
   "metadata": {},
   "source": [
    "UTILIZANDO MULTIPLO PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "31357e57-6b80-46f3-a8c7-14b2d12285b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_word_count= PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em até {n_palavras} palavras.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "template_line_count= PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em até {n_linhas} linhas.\n",
    "\"\"\")\n",
    "\n",
    "template_idioma = PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em {idioma}\n",
    "\"\"\")\n",
    "\n",
    "template_final = template_word_count + template_line_count +template_idioma+ \"Responda  a pergunta seguindo as instruçoes acima, pergunta:{pergunta}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ec87d-98a0-434e-99c7-396e125dfe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6589a619-3db7-4bf9-a07e-4e785b397ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_final = template_final.format(n_palavras=15,n_linhas=5, idioma=\"Francês\",pergunta=\"O que é langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d98b311-082f-40e8-9a84-429b1444ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responda a pergunta em até 15 palavras.\n",
      "\n",
      "Responda a pergunta em até 5 linhas.\n",
      "\n",
      "Responda a pergunta em Francês\n",
      "Responda  a pergunta seguindo as instruçoes acima, pergunta:O que é langchain\n"
     ]
    }
   ],
   "source": [
    "print(prompt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3e25e8a7-6a01-4f16-b15f-77c7765df2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLangchain est un système de gestion des langues pour les entreprises qui facilite la communication multilingue.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bd576-eeaf-4e96-a1e9-69cd71884cec",
   "metadata": {},
   "source": [
    "TEMPLATE PARA CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "34c570f1-f009-4b18-b73f-4f4b52ac679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bc24009d-cf42-4240-bb8c-5e373677a8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Minha dúvida:Quem é você', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_template(\"Minha dúvida:{dúvida}\")\n",
    "chat_template.format_messages(dúvida=\"Quem é você\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1a868ae6-238f-4053-a0f4-42ef50370120",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat2_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Você é um assistente  ironico e se chama {nome_assistente}\"),\n",
    "    (\"human\",\"Olá, como vai?\"),\n",
    "    (\"ai\",\"Estou bem , como posso lhe ajudar coisinha?\"),\n",
    "    (\"human\",\"{pergunta}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "81a0408f-dc9e-4745-90ea-842f3b02c5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['nome_assistente', 'pergunta'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['nome_assistente'], input_types={}, partial_variables={}, template='Você é um assistente  ironico e se chama {nome_assistente}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Olá, como vai?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Estou bem , como posso lhe ajudar coisinha?'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pergunta'], input_types={}, partial_variables={}, template='{pergunta}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat2_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "de2aec20-a1cc-4219-91b0-628e21bf2aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Você é um assistente  ironico e se chama JOEL', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Olá, como vai?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Estou bem , como posso lhe ajudar coisinha?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Qual seu nome?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat2_template.format_messages(nome_assistente=\"JOEL\",pergunta=\"Qual seu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3ad1e1ab-c1bf-41e1-bc4e-054ab56cf427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é JOEL, seu assistente sarcástico e cheio de charme. Como posso te ajudar hoje?\n"
     ]
    }
   ],
   "source": [
    "resposta=chat3.invoke(chat2_template.format_messages(nome_assistente=\"JOEL\",pergunta=\"Qual seu nome?\"))\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f79325-11aa-436a-8ef9-e88f5ce2d874",
   "metadata": {},
   "source": [
    "FEW_SHOT_PROMPTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "89349391-041d-4b25-b188-d5660746aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1475927c-99d9-4746-a772-d4031f32009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos=[{\"pergunta\":\"Quando nasceu Charles Darwin?\",\"resposta\":\" \"},\n",
    "          {\"pergunta\":\"Quem foi o pai de Napoleão Bonaparte?\",\"resposta\":\"\"},\n",
    "          {\"pergunta\":\"Quem foi Thomas Edson\",\"resposta\":\"\"}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6418a031-867e-4a2c-8935-a21feca165a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pergunta': 'Quando nasceu Charles Darwin?', 'resposta': ' '}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8b765a40-c1de-45e7-9557-43f301518419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta Quando nasceu Charles Darwin? \\n  '"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_promt = PromptTemplate(\n",
    "    input_variables=[\"pergunta\",\"resposta\"],\n",
    "    template=\"Pergunta {pergunta} \\n {resposta}\"\n",
    ")\n",
    "\n",
    "example_promt.format(**exemplos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6d0f17b6-0f8c-40b9-98e8-9cae1dbafedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=exemplos,\n",
    "    example_prompt=example_promt,\n",
    "    suffix=\"Pergunta:{input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d2b3dab4-97b1-40f0-96c5-c52907c00c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta Quando nasceu Charles Darwin? \n",
      "  \n",
      "\n",
      "Pergunta Quem foi o pai de Napoleão Bonaparte? \n",
      " \n",
      "\n",
      "Pergunta Quem foi Thomas Edson \n",
      " \n",
      "\n",
      "Pergunta:Quem é melhor , Messi ou CR7?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(input=\"Quem é melhor , Messi ou CR7?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7a1c389a-6ae9-4d65-9efd-52c8c302780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta=llm.invoke(prompt.format(input=\"Quem é melhor, Messi ou Cristiano ROnaldo?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f55eba97-3961-4a71-8dfa-eb95637a4c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6f32d-0f0e-49f8-bfe8-5399307979f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
