{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0059b7-445a-42e0-9444-cce481a3c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038a1613-eae7-4657-af84-27e034b72a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "chat = ChatOpenAI(api_key=os.getenv('OPENAI_API_KEY'),model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576b9d84-205c-4827-95c9-5e3abc104fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb5b1c6-7385-479f-9415-e63a91f9ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhos=[\"files/apostila.pdf\",\"files/LLM.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcde6db-4187-48d1-89e8-c2fd56395efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "paginas=[]\n",
    "for caminho in caminhos:\n",
    "    loader = PyPDFLoader(caminho)\n",
    "    paginas.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf17ee5f-b04e-4496-84f0-9dde4a8c0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\",\"\\n\",\".\",\" \",\"\"]\n",
    ")\n",
    "documents = rec_split.split_documents(paginas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecdb86b-3f36-44f6-bd50-08eaf4d165c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8 \\n  \\n3.3 Fatiamento de s trings  \\n \\nO fatiamento  é uma ferramenta usada para extrair apenas uma pa rte dos elementos de uma string . \\n \\n Nome_String [Limite_Inferior : Limite_Superior]  \\n \\nRetorna uma string com os elementos d as posições do limite inferior  até o limite superior - 1. \\n \\nExemplo:  \\n \\ns = \"Python\"  \\ns[1:4]   \\uf0e0 seleciona os elementos das posições 1,2,3   \\n\\'yth\\' \\n \\ns[2:]   \\uf0e0 seleciona os elementos a partir da posição 2   \\n\\'thon\\' \\n \\ns[:4]   \\uf0e0 seleciona os elementos até a posição 3   \\n\\'Pyth\\' \\n \\n3.4 Exercícios : strings  \\n \\n1 – Considere a string A = \"Um elefante incomoda  muita gente\" . Que fatia corresponde a \"elefante \\nincomoda \"? \\n \\n2 - Escreva um programa que solicite uma frase ao usuário e escreva a frase toda em mai úscula e \\nsem espaços em branco.  \\n  \\nreplace(S 1, S2) Substitui na string o trecho S1 pelo trecho S2 . n = \"Apostila teste\"  \\nn.replace(\"teste\", \"Python\")  \\n\\'Apostila Python\\'  \\n \\nfind()  Retorna o índice da primeira ocorrência de  um de-'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[22].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56aa9541-c4f1-46e3-b346-723ad722441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('arquivos/','')\n",
    "    doc.metadata['doc_id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a507d803-84ca-44eb-9ae7-d5150af452cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model= OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02056ee5-a981-4dda-b637-964dc4a49c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0799676c-5dff-4b9c-90f9-9deec52da4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    AQUI FOI CRIADO O BANCO  COM O CHROMA DB\n",
    "\n",
    "diretorio =\"arquivos/chat_retrival_db2\"\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding= embed_model,\n",
    "    persist_directory= diretorio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab1dbde-bf40-47db-884c-b18e4164ae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_chroma.vectorstores.Chroma object at 0x7f974dcf8310>\n"
     ]
    }
   ],
   "source": [
    "print(vector_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490ecf0-de3b-41ae-9038-5404f9f8c01f",
   "metadata": {},
   "source": [
    "agora criaremos o retrival para solicitações do arquivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5be20ab-53a9-4f8f-ac73-cbb345299c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd760fc-29f1-4083-89c0-13dc1efcac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever = vector_db.as_retriever(search_type='mmr'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746fc568-2863-4fa2-aaf2-96f9b3cd807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hungging face e como fazer para acessa-lo?',\n",
       " 'result': 'A Hugging Face é uma comunidade de código aberto que reúne centenas de milhares de modelos de contribuidores que podem ajudar a resolver muitos casos de uso específicos, como geração de texto, resumo e classificação. Para acessar a Hugging Face e seus modelos, você pode visitar o site deles em https://huggingface.co/ e explorar os modelos disponíveis, documentação e recursos fornecidos pela comunidade.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta =\"O que é Hungging face e como fazer para acessa-lo?\"\n",
    "\n",
    "chat_chain.invoke({\"query\":pergunta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "965546cd-f6f1-48c8-9e3f-d1e735acf659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt= PromptTemplate.from_template(\"\"\"\n",
    "Utilize o contexto fornecido para responder a pergunta ao final.\n",
    "Se você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\n",
    "Utilize trê frases no máximo, mantenha a resposta concisa.\n",
    "\n",
    "Contexto:{context}\n",
    "\n",
    "Pergunta:{question}\n",
    "\n",
    "Resposta:\n",
    "\"\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de171f-0444-42ed-b63b-7796b9a36c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6d01972-6eab-4055-99c4-29fd5c4aec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain= RetrievalQA.from_chain_type(\n",
    "    llm = chat,\n",
    "    retriever = vector_db.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type_kwargs={\"prompt\":chain_prompt},\n",
    "    return_source_documents = True,\n",
    "    \n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7236232b-2ca4-4a7c-b379-a9a3bfb25132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hungging face e como fazer para acessa-lo?',\n",
       " 'result': 'A Hugging Face é uma comunidade de código aberto que reúne centenas de milhares de modelos de contribuidores para resolver casos de uso específicos. Para acessá-la, você pode buscar por modelos de código aberto disponíveis no site da Hugging Face e utilizá-los em seu ambiente.',\n",
       " 'source_documents': [Document(page_content='Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados', metadata={'doc_id': 75, 'page': 6, 'source': 'files/LLM.pdf'}),\n",
       "  Document(page_content='. Além disso, devido aos recursos computacionais necessários, esses serviços não são gratuitos além de um uso muito limitado, então o custo se torna um fator ao aplicá-los em grande escala. Resumindo: serviços proprietários são ótimos para usar se você tiver tarefas muito complexas, tiver disposição para compartilhar seus dados com terceiros e quiser incorrer em custos ao operar em escala significativa.   Modelos de código aberto A outra opção para modelos de linguagem é recorrer à comunidade de código aberto, onde houve um crescimento igualmente explosivo nos últimos anos. Comunidades como a Hugging Face reúnem centenas de milhares de modelos de contribuidores que podem ajudar a resolver muitos casos de uso específicos, como geração de texto, resumo e classificação. A comunidade de código aberto está rapidamente alcançando o desempenho dos modelos proprietários, mas ainda não conseguiu igualar o desempenho de algo como o GPT-4.', metadata={'doc_id': 73, 'page': 5, 'source': 'files/LLM.pdf'}),\n",
       "  Document(page_content='PARTE 4 E agora, o que fazer se eu quiser começar a usar LLMs?    Isso depende de onde você está em sua jornada. Felizmente, temos algumas opções para você. Se você deseja se aprofundar um pouco mais nos LLMs, mas ainda não quer fazer isso por conta própria, pode assistir a uma das apresentações sob demanda de um dos desenvolvedores e palestrantes mais talentosos da Databricks sobre esses conceitos em mais detalhes, durante a palestra “Crie seu próprio grande modelo de linguagem como Dolly”. Se você quiser se aprofundar um pouco mais e expandir seus conhecimentos e compreensão dos fundamentos dos LLMs, recomendamos conferir nosso curso sobre LLMs. Você aprenderá como desenvolver aplicativos prontos para produção com LLMs e se aprofundará na teoria por trás dos modelos de fundação', metadata={'doc_id': 78, 'page': 7, 'source': 'files/LLM.pdf'}),\n",
       "  Document(page_content='. Notavelmente, um dos maiores saltos de desempenho veio da integração do feedback humano diretamente no processo de treinamento. MAIOR ACESSIBILIDADE  O lançamento do ChatGPT abriu as portas para qualquer pessoa com acesso à internet interagir com um dos LLMs mais avançados por meio de uma interface web simples. Isso trouxe os impressionantes avanços dos LLMs para o centro das atenções, uma vez que anteriormente esses modelos mais poderosos estavam disponíveis apenas para pesquisadores com recursos significativos e conhecimento técnico profundo.  AUMENTO DA POTÊNCIA COMPUTACIONAL  A disponibilidade de recursos de computação mais poderosos, como unidades de processamento gráfico (GPUs), e melhores técnicas de processamento de dados permitiu que os pesquisadores treinassem modelos muito maiores, melhorando o desempenho desses modelos de linguagem', metadata={'doc_id': 64, 'page': 3, 'source': 'files/LLM.pdf'})]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta =\"O que é Hungging face e como fazer para acessa-lo?\"\n",
    "\n",
    "chat_chain.invoke({\"query\":pergunta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e91f57b8-1a0c-46de-8f07-e41f977560df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['context', 'query']\n"
     ]
    }
   ],
   "source": [
    "print(chain_prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50664834-f2b3-42bc-b044-d2d401fa6098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma comunidade de código aberto que reúne modelos de contribuidores para resolver casos de uso específicos. Para acessá-lo, basta procurar por Hugging Face na internet e explorar os modelos disponíveis.\n"
     ]
    }
   ],
   "source": [
    "pergunta = \"O que é Huggin Face e como faço para acessá-lo?\"\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
